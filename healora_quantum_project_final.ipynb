{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db57ec0a-c20a-4d1d-8d6e-a0a98a794267",
   "metadata": {
    "id": "db57ec0a-c20a-4d1d-8d6e-a0a98a794267"
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "#Importing the quantum models.\n",
    "from qiskit.primitives import StatevectorSampler\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes, EfficientSU2, TwoLocal\n",
    "from qiskit_machine_learning.optimizers import COBYLA, SPSA, L_BFGS_B\n",
    "\n",
    "#Importing the classical models.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Loading sample datasets\n",
    "from sklearn.datasets import load_iris, make_classification, load_breast_cancer, load_wine\n",
    "\n",
    "#Imports for hyperparameter tuning.\n",
    "#from itertools import product\n",
    "#from sklearn.model_selection import ParameterGrid, cross_val_score\n",
    "#from collections import defaultdict\n",
    "\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "G9Pm4EGiqqSZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9Pm4EGiqqSZ",
    "outputId": "7b2a6f6d-340f-4d9b-a69c-5f573b52df37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING CONSISTENT DATASET ===\n",
      "Dataset shape: (150, 4)\n",
      "Training samples: 120, Test samples: 30\n",
      "Class distribution - Train: [60 60], Test: [15 15]\n"
     ]
    }
   ],
   "source": [
    "# Quantum imports\n",
    "from qiskit.primitives import StatevectorSampler\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN\n",
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes, EfficientSU2\n",
    "from qiskit_machine_learning.optimizers import COBYLA, SPSA\n",
    "\n",
    "# Classical imports for comparison\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# ========================================\n",
    "# FIXED DATA PREPARATION\n",
    "# ========================================\n",
    "print(\"=== CREATING CONSISTENT DATASET ===\")\n",
    "\n",
    "# Create the same synthetic dataset but with consistent preprocessing\n",
    "X, y = make_classification(\n",
    "    n_samples=150,\n",
    "    n_features=4,\n",
    "    n_redundant=0,\n",
    "    n_informative=4,\n",
    "    n_clusters_per_class=1,\n",
    "    class_sep=0.8,  # Slightly increased separation\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Consistent train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# CRITICAL: Apply consistent scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Training samples: {len(X_train_scaled)}, Test samples: {len(X_test_scaled)}\")\n",
    "print(f\"Class distribution - Train: {np.bincount(y_train)}, Test: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "r4mC8d0Rq2OR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4mC8d0Rq2OR",
    "outputId": "84a03822-20ee-48cd-877e-fc0edc67ad4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLASSICAL BASELINES ===\n",
      "Logistic Regression: 0.8667\n",
      "SVM: 0.9667\n",
      "Random Forest: 0.8000\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CLASSICAL BASELINE (CONSISTENT)\n",
    "# ========================================\n",
    "print(\"\\n=== CLASSICAL BASELINES ===\")\n",
    "\n",
    "classifiers = [\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=42, max_iter=1000)),\n",
    "    (\"SVM\", SVC(random_state=42, kernel='rbf')),\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "classical_results = {}\n",
    "for name, clf in classifiers:\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    classical_results[name] = acc\n",
    "    print(f\"{name}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b720f6-9ce5-4cbf-94bc-f7b39f8a7b89",
   "metadata": {
    "id": "99b720f6-9ce5-4cbf-94bc-f7b39f8a7b89"
   },
   "source": [
    "# Dataset Selection & Classical Model Training\n",
    "##### Currently, I imported already available datasets from scikit learn in order to make testing easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "716b3d74-9bdd-406b-8741-af2da1f5d76c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "716b3d74-9bdd-406b-8741-af2da1f5d76c",
    "outputId": "f6e06b27-e1ab-4694-db8e-305874fedf56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OPTION 1: Synthetic Challenging Dataset ===\n",
      "Logistic Regression accuracy on synthetic data: 0.756\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# DATASET OPTION 1: Synthetic Challenging Dataset\n",
    "# ========================================\n",
    "print(\"=== OPTION 1: Synthetic Challenging Dataset ===\")\n",
    "X_synth, y_synth = make_classification(\n",
    "    n_samples=150,          # Small dataset\n",
    "    n_features=4,           # 4 features (good for quantum)\n",
    "    n_redundant=0,          # No redundant features\n",
    "    n_informative=4,        # All features are informative\n",
    "    n_clusters_per_class=1, # One cluster per class\n",
    "    class_sep=0.6,          # Lower separation = harder problem\n",
    "    random_state=42\n",
    ")\n",
    "# Quick classical baseline test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_synth, y_synth, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "synth_score = lr.score(X_test_scaled, y_test)\n",
    "print(f\"Logistic Regression accuracy on synthetic data: {synth_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ac6a070-6d52-4f08-9948-fa84f859fc5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ac6a070-6d52-4f08-9948-fa84f859fc5c",
    "outputId": "253348ff-788e-47f2-ba3e-fa45d346239b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OPTION 2: Wine Dataset (Binary Classification) ===\n",
      "Logistic Regression accuracy on wine data: 0.926\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# DATASET OPTION 2: Wine Dataset (Reduced to Binary)\n",
    "# ========================================\n",
    "print(\"\\n=== OPTION 2: Wine Dataset (Binary Classification) ===\")\n",
    "wine_data = load_wine()\n",
    "X_wine, y_wine = wine_data.data, wine_data.target\n",
    "\n",
    "# Make it binary: Class 0 vs Classes 1&2\n",
    "y_wine_binary = (y_wine > 0).astype(int)\n",
    "\n",
    "# Use only first 4 features to keep it manageable for quantum\n",
    "X_wine_4feat = X_wine[:, :4]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_wine_4feat, y_wine_binary, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "wine_score = lr.score(X_test_scaled, y_test)\n",
    "print(f\"Logistic Regression accuracy on wine data: {wine_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "207193e3-255c-4f1a-aea8-9a01e710c302",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "207193e3-255c-4f1a-aea8-9a01e710c302",
    "outputId": "525e0eb6-b38a-49a9-93e9-131cb15b8841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OPTION 3: Breast Cancer Dataset (4 features) ===\n",
      "Logistic Regression accuracy on cancer subset: 0.918\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# DATASET OPTION 3: Breast Cancer (Subset of Features)\n",
    "# ========================================\n",
    "print(\"\\n=== OPTION 3: Breast Cancer Dataset (4 features) ===\")\n",
    "cancer_data = load_breast_cancer()\n",
    "X_cancer, y_cancer = cancer_data.data, cancer_data.target\n",
    "\n",
    "# Select 4 features that are known to be less predictive\n",
    "# (avoiding the most discriminative ones)\n",
    "feature_indices = [2, 7, 12, 17]  # Some texture and fractal dimension features\n",
    "X_cancer_4feat = X_cancer[:, feature_indices]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer_4feat, y_cancer, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "cancer_score = lr.score(X_test_scaled, y_test)\n",
    "print(f\"Logistic Regression accuracy on cancer subset: {cancer_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a3a3b-c6a7-4890-be9a-be49a00d2f03",
   "metadata": {
    "id": "d69a3a3b-c6a7-4890-be9a-be49a00d2f03"
   },
   "source": [
    "##### Above, I have trained a classical logical regression model on pre-available datasets to check for accuracy and determine the model that returns an average accuracy. I specifically select a dataset which produces average to check if a quantum model can help improve that accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61a45a00-4723-431e-a535-96e4f061f588",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61a45a00-4723-431e-a535-96e4f061f588",
    "outputId": "da34d88a-f562-4893-bd9a-a51303327636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RECOMMENDATION ===\n",
      "Recommended dataset: Synthetic (accuracy: 0.756)\n",
      "This provides a good baseline that quantum models might be able to improve upon.\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# RECOMMENDATION\n",
    "# ========================================\n",
    "print(\"\\n=== RECOMMENDATION ===\")\n",
    "scores = [synth_score, wine_score, cancer_score]\n",
    "names = [\"Synthetic\", \"Wine\", \"Cancer subset\"]\n",
    "\n",
    "# Find the dataset with most \"average\" performance (closest to 0.75-0.85 range)\n",
    "target_range = (0.75, 0.85)\n",
    "best_idx = 0\n",
    "best_distance = float('inf')\n",
    "\n",
    "for i, score in enumerate(scores):\n",
    "    if target_range[0] <= score <= target_range[1]:\n",
    "        distance = abs(score - 0.8)  # Distance from ideal \"average\" score\n",
    "        if distance < best_distance:\n",
    "            best_distance = distance\n",
    "            best_idx = i\n",
    "\n",
    "print(f\"Recommended dataset: {names[best_idx]} (accuracy: {scores[best_idx]:.3f})\")\n",
    "print(\"This provides a good baseline that quantum models might be able to improve upon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea7652-95dc-4d67-9b7e-cfcb93bbcd49",
   "metadata": {
    "id": "74ea7652-95dc-4d67-9b7e-cfcb93bbcd49"
   },
   "source": [
    "##### The synthetic dataset (Dataset no.1) has produced an average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33214c2c-3b3f-41de-a1b4-beac88ca6ca7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33214c2c-3b3f-41de-a1b4-beac88ca6ca7",
    "outputId": "9b4c4794-320d-4b55-e83c-603370bf20c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 'Synthetic' is ready to use:\n",
      "Features shape: (150, 4)\n",
      "Labels shape: (150,)\n",
      "Classes: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# READY-TO-USE DATASET VARIABLES\n",
    "# ========================================\n",
    "if best_idx == 0:\n",
    "    X_final, y_final = X_synth, y_synth\n",
    "    dataset_name = \"Synthetic\"\n",
    "elif best_idx == 1:\n",
    "    X_final, y_final = X_wine_4feat, y_wine_binary\n",
    "    dataset_name = \"Wine\"\n",
    "else:\n",
    "    X_final, y_final = X_cancer_4feat, y_cancer\n",
    "    dataset_name = \"Cancer subset\"\n",
    "\n",
    "print(f\"\\nDataset '{dataset_name}' is ready to use:\")\n",
    "print(f\"Features shape: {X_final.shape}\")\n",
    "print(f\"Labels shape: {y_final.shape}\")\n",
    "print(f\"Classes: {np.unique(y_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7287d71b-6e04-4b69-9269-6fb4e7305956",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7287d71b-6e04-4b69-9269-6fb4e7305956",
    "outputId": "bfdf15d4-c1b6-4201-d73a-c54ec5098c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 120, Test samples: 30\n",
      "Feature dimensions: 4\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data.\n",
    "X, y = X_final, y_final\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "print(f\"Feature dimensions: {X_train.shape[1]}\") #should be limited, we will try with only 4 features for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc04c0-4554-4fe3-b061-33ea08ca7cd8",
   "metadata": {
    "id": "a1dc04c0-4554-4fe3-b061-33ea08ca7cd8"
   },
   "source": [
    "##### The number of qubits to be used in the simulation will be the same as the number of features being used in the dataset. For this exercise, I have chosen to use 4 features and 4 qubits to closely simulate realo-life situations of limited resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7508762b-34d9-49af-9429-b7eef815fab4",
   "metadata": {
    "id": "7508762b-34d9-49af-9429-b7eef815fab4"
   },
   "outputs": [],
   "source": [
    "num_qubits = X_train.shape[1]  # use number of features as qubits\n",
    "feature_map = ZZFeatureMap(num_qubits, reps=1)        # encodes classical data\n",
    "ansatz = RealAmplitudes(num_qubits, reps=1)           # variational layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "efbb248c-f6ed-4f2d-94ae-370bb84163cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "efbb248c-f6ed-4f2d-94ae-370bb84163cb",
    "outputId": "6d8bf749-97fe-4bac-ec83-0c70a681d00e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    }
   ],
   "source": [
    "# Creating the sampler.\n",
    "sampler = StatevectorSampler()\n",
    "\n",
    "# Create the SamplerQNN\n",
    "qnn = SamplerQNN(\n",
    "    circuit=feature_map.compose(ansatz),\n",
    "    input_params=feature_map.parameters,\n",
    "    weight_params=ansatz.parameters,\n",
    "    sampler=sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd7d8cc7-7d49-461f-a067-14423c311096",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd7d8cc7-7d49-461f-a067-14423c311096",
    "outputId": "eb3d47cb-5797-47eb-c1b9-a33e148af934"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    }
   ],
   "source": [
    "# Define VQC\n",
    "optimizer = COBYLA(maxiter=50)\n",
    "\n",
    "# Create VQC with the correct API\n",
    "vqc = VQC(\n",
    "    sampler=sampler,\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6cc49-4b70-42ea-8bbd-89ef318e9825",
   "metadata": {
    "id": "ebe6cc49-4b70-42ea-8bbd-89ef318e9825"
   },
   "source": [
    "##### Training a Variational Quantum Classifier, the quantum equivalent of a binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31d3271e-d9e1-4ad7-8108-cfdd9d33c148",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31d3271e-d9e1-4ad7-8108-cfdd9d33c148",
    "outputId": "f8d7661c-38d2-46e2-8402-6f0df9603103"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training VQC...\n",
      "Making predictions...\n",
      "Quantum Variational Classifier Accuracy: 0.5667\n",
      "Predictions: [0 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 1 1]\n",
      "Actual:      [1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "#Training and evaluation\n",
    "\n",
    "#VQC\n",
    "print(\"Training VQC...\")\n",
    "vqc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "y_pred = vqc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Quantum Variational Classifier Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Additional metrics\n",
    "print(f\"Predictions: {y_pred}\")\n",
    "print(f\"Actual:      {y_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a8de85-f8a9-4dc4-8dfb-a3580007289c",
   "metadata": {
    "id": "15a8de85-f8a9-4dc4-8dfb-a3580007289c"
   },
   "source": [
    "##### The very first iteration produced an accuracy of 43%. Upon later iterations, the accuracy increased to 53% which is only as good as a randomised guess. Below, we attempt to improve this accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fbbef383-7a06-44fc-bf02-50f92fc8d760",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbbef383-7a06-44fc-bf02-50f92fc8d760",
    "outputId": "fd901c2b-d571-445e-8e98-7621bd5e383f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMPROVING QUANTUM MODEL PERFORMANCE ===\n",
      "\n",
      "--- Attempt 1: Deeper circuit + More iterations ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4333 (Training time: 171.2s)\n",
      "\n",
      "--- Attempt 2: EfficientSU2 ansatz ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4333 (Training time: 176.7s)\n",
      "\n",
      "--- Attempt 3: SPSA optimizer ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5667 (Training time: 219.5s)\n",
      "\n",
      "--- Attempt 4: Multiple random initializations ---\n",
      "  Random start 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4667\n",
      "  Random start 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6000\n",
      "  Random start 3/3... Accuracy: 0.5667\n",
      "Best accuracy from multiple starts: 0.6000\n",
      "\n",
      "=== RESULTS SUMMARY ===\n",
      "Method                | Accuracy\n",
      "-----------------------------------\n",
      "Original (shallow)   | 0.4333\n",
      "Deeper circuit       | 0.4333\n",
      "EfficientSU2         | 0.4333\n",
      "SPSA optimizer       | 0.5667\n",
      "Multiple starts      | 0.6000\n",
      "\n",
      "Best method: Multiple starts with 0.6000 accuracy\n",
      "\n",
      "=== CLASSICAL BASELINE COMPARISON ===\n",
      "Classical Method      | Accuracy\n",
      "-----------------------------------\n",
      "Logistic Regression  | 0.8000\n",
      "SVM                  | 0.9000\n",
      "Random Forest        | 0.8333\n",
      "\n",
      "Quantum best:         | 0.6000\n"
     ]
    }
   ],
   "source": [
    "print(\"=== IMPROVING QUANTUM MODEL PERFORMANCE ===\")\n",
    "\n",
    "# -----------------------------\n",
    "# Try 1: More iterations and deeper circuit\n",
    "# -----------------------------\n",
    "print(\"\\n--- Attempt 1: Deeper circuit + More iterations ---\")\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)  # More reps\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps=3)  # Deeper ansatz\n",
    "\n",
    "sampler = StatevectorSampler()\n",
    "optimizer = COBYLA(maxiter=200)  # More iterations\n",
    "\n",
    "vqc1 = VQC(\n",
    "    sampler=sampler,\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "vqc1.fit(X_train, y_train)\n",
    "training_time1 = time.time() - start_time\n",
    "\n",
    "y_pred1 = vqc1.predict(X_test)\n",
    "acc1 = accuracy_score(y_test, y_pred1)\n",
    "print(f\"Accuracy: {acc1:.4f} (Training time: {training_time1:.1f}s)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Try 2: Different ansatz (EfficientSU2)\n",
    "# -----------------------------\n",
    "print(\"\\n--- Attempt 2: EfficientSU2 ansatz ---\")\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
    "ansatz = EfficientSU2(num_qubits=num_features, reps=2)  # Different ansatz\n",
    "\n",
    "optimizer = COBYLA(maxiter=150)\n",
    "\n",
    "vqc2 = VQC(\n",
    "    sampler=sampler,\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "vqc2.fit(X_train, y_train)\n",
    "training_time2 = time.time() - start_time\n",
    "\n",
    "y_pred2 = vqc2.predict(X_test)\n",
    "acc2 = accuracy_score(y_test, y_pred2)\n",
    "print(f\"Accuracy: {acc2:.4f} (Training time: {training_time2:.1f}s)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Try 3: Different optimizer (SPSA)\n",
    "# -----------------------------\n",
    "print(\"\\n--- Attempt 3: SPSA optimizer ---\")\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps=2)\n",
    "\n",
    "optimizer = SPSA(maxiter=100, learning_rate=0.1, perturbation=0.1)\n",
    "\n",
    "vqc3 = VQC(\n",
    "    sampler=sampler,\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "vqc3.fit(X_train, y_train)\n",
    "training_time3 = time.time() - start_time\n",
    "\n",
    "y_pred3 = vqc3.predict(X_test)\n",
    "acc3 = accuracy_score(y_test, y_pred3)\n",
    "print(f\"Accuracy: {acc3:.4f} (Training time: {training_time3:.1f}s)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Try 4: Multiple random starts (best practice)\n",
    "# -----------------------------\n",
    "print(\"\\n--- Attempt 4: Multiple random initializations ---\")\n",
    "best_acc = 0\n",
    "best_model = None\n",
    "best_pred = None\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps=2)\n",
    "optimizer = COBYLA(maxiter=100)\n",
    "\n",
    "for i in range(3):  # Try 3 different random starts\n",
    "    print(f\"  Random start {i+1}/3...\", end=\" \")\n",
    "\n",
    "    vqc_temp = VQC(\n",
    "        sampler=sampler,\n",
    "        feature_map=feature_map,\n",
    "        ansatz=ansatz,\n",
    "        optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    # Set different random seed for each attempt\n",
    "    np.random.seed(42 + i * 10)\n",
    "\n",
    "    vqc_temp.fit(X_train, y_train)\n",
    "    y_pred_temp = vqc_temp.predict(X_test)\n",
    "    acc_temp = accuracy_score(y_test, y_pred_temp)\n",
    "\n",
    "    print(f\"Accuracy: {acc_temp:.4f}\")\n",
    "\n",
    "    if acc_temp > best_acc:\n",
    "        best_acc = acc_temp\n",
    "        best_model = vqc_temp\n",
    "        best_pred = y_pred_temp\n",
    "\n",
    "print(f\"Best accuracy from multiple starts: {best_acc:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Summary and Comparison\n",
    "# -----------------------------\n",
    "print(\"\\n=== RESULTS SUMMARY ===\")\n",
    "results = [\n",
    "    (\"Original (shallow)\", 0.4333),  # Your original result\n",
    "    (\"Deeper circuit\", acc1),\n",
    "    (\"EfficientSU2\", acc2),\n",
    "    (\"SPSA optimizer\", acc3),\n",
    "    (\"Multiple starts\", best_acc)\n",
    "]\n",
    "\n",
    "print(\"Method                | Accuracy\")\n",
    "print(\"-\" * 35)\n",
    "for method, acc in results:\n",
    "    print(f\"{method:<20} | {acc:.4f}\")\n",
    "\n",
    "# Find best performing model\n",
    "best_method_idx = np.argmax([r[1] for r in results])\n",
    "print(f\"\\nBest method: {results[best_method_idx][0]} with {results[best_method_idx][1]:.4f} accuracy\")\n",
    "\n",
    "# -----------------------------\n",
    "# Classical Baseline for Comparison\n",
    "# -----------------------------\n",
    "print(\"\\n=== CLASSICAL BASELINE COMPARISON ===\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifiers = [\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=42)),\n",
    "    (\"SVM\", SVC(random_state=42)),\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=50, random_state=42))\n",
    "]\n",
    "\n",
    "print(\"Classical Method      | Accuracy\")\n",
    "print(\"-\" * 35)\n",
    "for name, clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_classical = clf.predict(X_test)\n",
    "    acc_classical = accuracy_score(y_test, y_pred_classical)\n",
    "    print(f\"{name:<20} | {acc_classical:.4f}\")\n",
    "\n",
    "print(f\"\\nQuantum best:         | {results[best_method_idx][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2fe1917b-ffb9-4ad8-a643-145b70602cdf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2fe1917b-ffb9-4ad8-a643-145b70602cdf",
    "outputId": "b0c1974c-0ab7-475f-beb9-06be30733d6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Attempt 2: EfficientSU2 ansatz ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5333 (Training time: 173.5s)\n",
      "\n",
      "--- Attempt 3: SPSA optimizer ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6333 (Training time: 217.0s)\n",
      "\n",
      "--- Attempt 4: Multiple random initializations ---\n",
      "  Random start 1/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6000\n",
      "  Random start 2/3... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6333\n",
      "  Random start 3/3... Accuracy: 0.5667\n",
      "Best accuracy from multiple starts: 0.6333\n",
      "\n",
      "=== RESULTS SUMMARY ===\n",
      "Method                | Accuracy\n",
      "-----------------------------------\n",
      "Original (shallow)   | 0.4333\n",
      "Deeper circuit       | 0.4333\n",
      "EfficientSU2         | 0.5333\n",
      "SPSA optimizer       | 0.6333\n",
      "Multiple starts      | 0.6333\n",
      "\n",
      "Best method: SPSA optimizer with 0.6333 accuracy\n",
      "\n",
      "=== CLASSICAL BASELINE COMPARISON ===\n",
      "Classical Method      | Accuracy\n",
      "-----------------------------------\n",
      "Logistic Regression  | 0.8000\n",
      "SVM                  | 0.9000\n",
      "Random Forest        | 0.8333\n",
      "\n",
      "Quantum best:         | 0.6333\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Try 2: Different ansatz (EfficientSU2)\n",
    "# -----------------------------\n",
    "print(\"\\n--- Attempt 2: EfficientSU2 ansatz ---\")\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
    "ansatz = EfficientSU2(num_qubits=num_features, reps=2)  # Different ansatz\n",
    "\n",
    "optimizer = COBYLA(maxiter=150)\n",
    "\n",
    "vqc2 = VQC(\n",
    "    sampler=sampler,\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "vqc2.fit(X_train, y_train)\n",
    "training_time2 = time.time() - start_time\n",
    "\n",
    "y_pred2 = vqc2.predict(X_test)\n",
    "acc2 = accuracy_score(y_test, y_pred2)\n",
    "print(f\"Accuracy: {acc2:.4f} (Training time: {training_time2:.1f}s)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Try 3: Different optimizer (SPSA)\n",
    "# -----------------------------\n",
    "print(\"\\n--- Attempt 3: SPSA optimizer ---\")\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps=2)\n",
    "\n",
    "optimizer = SPSA(maxiter=100, learning_rate=0.1, perturbation=0.1)\n",
    "\n",
    "vqc3 = VQC(\n",
    "    sampler=sampler,\n",
    "    feature_map=feature_map,\n",
    "    ansatz=ansatz,\n",
    "    optimizer=optimizer\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "vqc3.fit(X_train, y_train)\n",
    "training_time3 = time.time() - start_time\n",
    "\n",
    "y_pred3 = vqc3.predict(X_test)\n",
    "acc3 = accuracy_score(y_test, y_pred3)\n",
    "print(f\"Accuracy: {acc3:.4f} (Training time: {training_time3:.1f}s)\")\n",
    "\n",
    "# -----------------------------\n",
    "# Try 4: Multiple random starts (best practice)\n",
    "# -----------------------------\n",
    "print(\"\\n--- Attempt 4: Multiple random initializations ---\")\n",
    "best_acc = 0\n",
    "best_model = None\n",
    "best_pred = None\n",
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension=num_features, reps=2)\n",
    "ansatz = RealAmplitudes(num_qubits=num_features, reps=2)\n",
    "optimizer = COBYLA(maxiter=100)\n",
    "\n",
    "for i in range(3):  # Try 3 different random starts\n",
    "    print(f\"  Random start {i+1}/3...\", end=\" \")\n",
    "\n",
    "    vqc_temp = VQC(\n",
    "        sampler=sampler,\n",
    "        feature_map=feature_map,\n",
    "        ansatz=ansatz,\n",
    "        optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    # Set different random seed for each attempt\n",
    "    np.random.seed(42 + i * 10)\n",
    "\n",
    "    vqc_temp.fit(X_train, y_train)\n",
    "    y_pred_temp = vqc_temp.predict(X_test)\n",
    "    acc_temp = accuracy_score(y_test, y_pred_temp)\n",
    "\n",
    "    print(f\"Accuracy: {acc_temp:.4f}\")\n",
    "\n",
    "    if acc_temp > best_acc:\n",
    "        best_acc = acc_temp\n",
    "        best_model = vqc_temp\n",
    "        best_pred = y_pred_temp\n",
    "\n",
    "print(f\"Best accuracy from multiple starts: {best_acc:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Summary and Comparison\n",
    "# -----------------------------\n",
    "print(\"\\n=== RESULTS SUMMARY ===\")\n",
    "results = [\n",
    "    (\"Original (shallow)\", 0.4333),  # Your original result\n",
    "    (\"Deeper circuit\", acc1),\n",
    "    (\"EfficientSU2\", acc2),\n",
    "    (\"SPSA optimizer\", acc3),\n",
    "    (\"Multiple starts\", best_acc)\n",
    "]\n",
    "\n",
    "print(\"Method                | Accuracy\")\n",
    "print(\"-\" * 35)\n",
    "for method, acc in results:\n",
    "    print(f\"{method:<20} | {acc:.4f}\")\n",
    "\n",
    "# Find best performing model\n",
    "best_method_idx = np.argmax([r[1] for r in results])\n",
    "print(f\"\\nBest method: {results[best_method_idx][0]} with {results[best_method_idx][1]:.4f} accuracy\")\n",
    "\n",
    "# -----------------------------\n",
    "# Classical Baseline for Comparison\n",
    "# -----------------------------\n",
    "print(\"\\n=== CLASSICAL BASELINE COMPARISON ===\")\n",
    "\n",
    "classifiers = [\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=42)),\n",
    "    (\"SVM\", SVC(random_state=42)),\n",
    "    (\"Random Forest\", RandomForestClassifier(n_estimators=50, random_state=42))\n",
    "]\n",
    "\n",
    "print(\"Classical Method      | Accuracy\")\n",
    "print(\"-\" * 35)\n",
    "for name, clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_classical = clf.predict(X_test)\n",
    "    acc_classical = accuracy_score(y_test, y_pred_classical)\n",
    "    print(f\"{name:<20} | {acc_classical:.4f}\")\n",
    "\n",
    "print(f\"\\nQuantum best:         | {results[best_method_idx][1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f4e519-5518-4d27-8585-4605fc844621",
   "metadata": {
    "id": "a2f4e519-5518-4d27-8585-4605fc844621"
   },
   "source": [
    "# **HYPERPARAMETER TUNING**\n",
    "##### This part of the notebook is computing intensive. Please do not run this unless you are ready to wait a couple of hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2afb6791-2396-444e-8154-a6fc2bdea8a2",
   "metadata": {
    "id": "2afb6791-2396-444e-8154-a6fc2bdea8a2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from itertools import product\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_score\n",
    "from qiskit.primitives import StatevectorSampler\n",
    "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes, EfficientSU2, TwoLocal\n",
    "from qiskit_machine_learning.optimizers import COBYLA, SPSA, L_BFGS_B\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "451d0e29-e63b-4f97-885d-d968e2abb669",
   "metadata": {
    "id": "451d0e29-e63b-4f97-885d-d968e2abb669",
    "outputId": "3fb58627-6886-4ab8-b35c-0fce1eb3480e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPREHENSIVE QUANTUM ML HYPERPARAMETER TUNING ===\n",
      "\n",
      "1. Grid Search for Core Quantum Parameters\n",
      "This will take a while - testing multiple combinations...\n",
      "Total combinations to test: 72\n"
     ]
    }
   ],
   "source": [
    "print(\"=== COMPREHENSIVE QUANTUM ML HYPERPARAMETER TUNING ===\")\n",
    "\n",
    "# Assume X_train, X_test, y_train, y_test are already defined\n",
    "\n",
    "# -----------------------------\n",
    "# 1. GRID SEARCH FOR CORE PARAMETERS\n",
    "# -----------------------------\n",
    "print(\"\\n1. Grid Search for Core Quantum Parameters\")\n",
    "print(\"This will take a while - testing multiple combinations...\")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'feature_map_reps': [1, 2, 3],\n",
    "    'ansatz_reps': [1, 2, 3, 4],\n",
    "    'optimizer_maxiter': [50, 100, 200],\n",
    "    'ansatz_type': ['RealAmplitudes', 'EfficientSU2']\n",
    "}\n",
    "\n",
    "print(f\"Total combinations to test: {len(list(ParameterGrid(param_grid)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47f7d1b8-3d6b-45d1-8e16-2f661bb623a1",
   "metadata": {
    "id": "47f7d1b8-3d6b-45d1-8e16-2f661bb623a1",
    "outputId": "768fa6f2-9590-41a4-899a-211a8d229c9f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 1/72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 11/72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 21/72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 31/72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 41/72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 51/72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 61/72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n",
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Progress: 71/72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search complete! Best score: 0.8000\n",
      "Best parameters: {'ansatz_reps': 2, 'ansatz_type': 'EfficientSU2', 'feature_map_reps': 2, 'optimizer_maxiter': 50}\n"
     ]
    }
   ],
   "source": [
    "# Store results\n",
    "grid_results = []\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "# Grid search\n",
    "for i, params in enumerate(ParameterGrid(param_grid)):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"  Progress: {i+1}/{len(list(ParameterGrid(param_grid)))}\")\n",
    "\n",
    "    # Create feature map\n",
    "    feature_map = ZZFeatureMap(\n",
    "        feature_dimension=4,\n",
    "        reps=params['feature_map_reps']\n",
    "    )\n",
    "\n",
    "    # Create ansatz\n",
    "    if params['ansatz_type'] == 'RealAmplitudes':\n",
    "        ansatz = RealAmplitudes(num_qubits=4, reps=params['ansatz_reps'])\n",
    "    else:\n",
    "        ansatz = EfficientSU2(num_qubits=4, reps=params['ansatz_reps'])\n",
    "\n",
    "    # Create optimizer\n",
    "    optimizer = COBYLA(maxiter=params['optimizer_maxiter'])\n",
    "\n",
    "    try:\n",
    "        # Create and train VQC\n",
    "        vqc = VQC(\n",
    "            sampler=StatevectorSampler(),\n",
    "            feature_map=feature_map,\n",
    "            ansatz=ansatz,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "\n",
    "        # Train with timeout protection\n",
    "        start_time = time.time()\n",
    "        vqc.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = vqc.predict(X_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Store results\n",
    "        result = {\n",
    "            'params': params.copy(),\n",
    "            'score': score,\n",
    "            'training_time': training_time\n",
    "        }\n",
    "        grid_results.append(result)\n",
    "\n",
    "        # Update best\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = params.copy()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    Error with params {params}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Grid search complete! Best score: {best_score:.4f}\")\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e1c3623-2991-4a63-b964-3eb7d12f33bb",
   "metadata": {
    "id": "1e1c3623-2991-4a63-b964-3eb7d12f33bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Fine-tuning Optimizer Parameters\n",
      "  Testing COBYLA_conservative... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6667, Time: 235.6s\n",
      "  Testing COBYLA_aggressive... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3000, Time: 117.5s\n",
      "  Testing SPSA_slow_learning... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4667, Time: 354.0s\n",
      "  Testing SPSA_fast_learning... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5000, Time: 236.4s\n",
      "  Testing SPSA_adaptive... Score: 0.5667, Time: 354.9s\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2. OPTIMIZER-SPECIFIC TUNING\n",
    "# -----------------------------\n",
    "print(\"\\n2. Fine-tuning Optimizer Parameters\")\n",
    "\n",
    "optimizer_configs = [\n",
    "    # COBYLA variants\n",
    "    {\n",
    "        'name': 'COBYLA_conservative',\n",
    "        'optimizer': COBYLA(maxiter=200, tol=1e-8, disp=False)\n",
    "    },\n",
    "    {\n",
    "        'name': 'COBYLA_aggressive',\n",
    "        'optimizer': COBYLA(maxiter=100, tol=1e-4, disp=False)\n",
    "    },\n",
    "    # SPSA variants\n",
    "    {\n",
    "        'name': 'SPSA_slow_learning',\n",
    "        'optimizer': SPSA(maxiter=150, learning_rate=0.01, perturbation=0.05)\n",
    "    },\n",
    "    {\n",
    "        'name': 'SPSA_fast_learning',\n",
    "        'optimizer': SPSA(maxiter=100, learning_rate=0.1, perturbation=0.2)\n",
    "    },\n",
    "    {\n",
    "        'name': 'SPSA_adaptive',\n",
    "        'optimizer': SPSA(maxiter=150, learning_rate=0.05, perturbation=0.1)\n",
    "    },\n",
    "]\n",
    "\n",
    "optimizer_results = {}\n",
    "\n",
    "# Use best architecture from grid search\n",
    "if best_params:\n",
    "    feature_map = ZZFeatureMap(feature_dimension=4, reps=best_params['feature_map_reps'])\n",
    "    if best_params['ansatz_type'] == 'RealAmplitudes':\n",
    "        ansatz = RealAmplitudes(num_qubits=4, reps=best_params['ansatz_reps'])\n",
    "    else:\n",
    "        ansatz = EfficientSU2(num_qubits=4, reps=best_params['ansatz_reps'])\n",
    "else:\n",
    "    # Fallback if grid search failed\n",
    "    feature_map = ZZFeatureMap(feature_dimension=4, reps=2)\n",
    "    ansatz = RealAmplitudes(num_qubits=4, reps=2)\n",
    "\n",
    "for config in optimizer_configs:\n",
    "    print(f\"  Testing {config['name']}...\", end=\" \")\n",
    "\n",
    "    try:\n",
    "        vqc_opt = VQC(\n",
    "            sampler=StatevectorSampler(),\n",
    "            feature_map=feature_map,\n",
    "            ansatz=ansatz,\n",
    "            optimizer=config['optimizer']\n",
    "        )\n",
    "\n",
    "        start_time = time.time()\n",
    "        vqc_opt.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        y_pred = vqc_opt.predict(X_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        optimizer_results[config['name']] = {\n",
    "            'score': score,\n",
    "            'time': training_time\n",
    "        }\n",
    "\n",
    "        print(f\"Score: {score:.4f}, Time: {training_time:.1f}s\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0149deee-ac0f-4b9f-9ada-17c83554b040",
   "metadata": {
    "id": "0149deee-ac0f-4b9f-9ada-17c83554b040"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Random Search for Fine-tuning\n",
      "  Random trial 1/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6000\n",
      "  Random trial 2/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4667\n",
      "  Random trial 3/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4333\n",
      "  Random trial 4/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6000\n",
      "  Random trial 5/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4333\n",
      "  Random trial 6/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4333\n",
      "  Random trial 7/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5333\n",
      "  Random trial 8/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4667\n",
      "  Random trial 9/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5667\n",
      "  Random trial 10/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5667\n",
      "  Random trial 11/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5000\n",
      "  Random trial 12/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4000\n",
      "  Random trial 13/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4667\n",
      "  Random trial 14/15: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5667\n",
      "  Random trial 15/15: Score: 0.5667\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. RANDOM SEARCH WITH BUDGET\n",
    "# -----------------------------\n",
    "print(\"\\n3. Random Search for Fine-tuning\")\n",
    "\n",
    "def random_search(n_iterations=20):\n",
    "    \"\"\"Random search with larger parameter space\"\"\"\n",
    "\n",
    "    random_results = []\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        # Random parameter selection\n",
    "        params = {\n",
    "            'feature_map_reps': np.random.choice([1, 2, 3, 4]),\n",
    "            'ansatz_reps': np.random.choice([1, 2, 3, 4, 5]),\n",
    "            'optimizer': np.random.choice(['COBYLA', 'SPSA']),\n",
    "            'maxiter': np.random.choice([50, 75, 100, 150, 200]),\n",
    "        }\n",
    "\n",
    "        # COBYLA-specific parameters\n",
    "        if params['optimizer'] == 'COBYLA':\n",
    "            params['tol'] = 10**np.random.uniform(-8, -3)\n",
    "            optimizer = COBYLA(maxiter=params['maxiter'], tol=params['tol'])\n",
    "\n",
    "        # SPSA-specific parameters\n",
    "        else:\n",
    "            params['learning_rate'] = 10**np.random.uniform(-2, -0.5)\n",
    "            params['perturbation'] = 10**np.random.uniform(-2, -0.5)\n",
    "            optimizer = SPSA(\n",
    "                maxiter=params['maxiter'],\n",
    "                learning_rate=params['learning_rate'],\n",
    "                perturbation=params['perturbation']\n",
    "            )\n",
    "\n",
    "        print(f\"  Random trial {i+1}/{n_iterations}: \", end=\"\")\n",
    "\n",
    "        try:\n",
    "            # Create components\n",
    "            feature_map = ZZFeatureMap(feature_dimension=4, reps=params['feature_map_reps'])\n",
    "            ansatz_type = np.random.choice(['RealAmplitudes', 'EfficientSU2'])\n",
    "\n",
    "            if ansatz_type == 'RealAmplitudes':\n",
    "                ansatz = RealAmplitudes(num_qubits=4, reps=params['ansatz_reps'])\n",
    "            else:\n",
    "                ansatz = EfficientSU2(num_qubits=4, reps=params['ansatz_reps'])\n",
    "\n",
    "            params['ansatz_type'] = ansatz_type\n",
    "\n",
    "            # Train and evaluate\n",
    "            vqc_random = VQC(\n",
    "                sampler=StatevectorSampler(),\n",
    "                feature_map=feature_map,\n",
    "                ansatz=ansatz,\n",
    "                optimizer=optimizer\n",
    "            )\n",
    "\n",
    "            vqc_random.fit(X_train, y_train)\n",
    "            y_pred = vqc_random.predict(X_test)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            random_results.append({\n",
    "                'params': params,\n",
    "                'score': score\n",
    "            })\n",
    "\n",
    "            print(f\"Score: {score:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed: {str(e)[:50]}...\")\n",
    "\n",
    "    return random_results\n",
    "\n",
    "random_results = random_search(n_iterations=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a35e7c8d-492a-423b-9737-399dade39ba7",
   "metadata": {
    "id": "a35e7c8d-492a-423b-9737-399dade39ba7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Adaptive Parameter Tuning (Bayesian-style)\n",
      "  Adaptive iteration 1/10: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.3333\n",
      "  Adaptive iteration 2/10: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4333\n",
      "  Adaptive iteration 3/10: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4333\n",
      "  Adaptive iteration 4/10: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4667\n",
      "  Adaptive iteration 5/10: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.5333\n",
      "  Adaptive iteration 6/10: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4333\n",
      "  Adaptive iteration 7/10: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4667\n",
      "  Adaptive iteration 8/10: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6000\n",
      "  Adaptive iteration 9/10: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.4000\n",
      "  Adaptive iteration 10/10: Score: 0.4333\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4. ADAPTIVE PARAMETER TUNING\n",
    "# -----------------------------\n",
    "print(\"\\n4. Adaptive Parameter Tuning (Bayesian-style)\")\n",
    "\n",
    "def adaptive_tuning(n_iterations=10):\n",
    "    \"\"\"Simple adaptive tuning based on previous results\"\"\"\n",
    "\n",
    "    # Start with best known parameters\n",
    "    if best_params:\n",
    "        current_best = best_params.copy()\n",
    "        current_score = best_score\n",
    "    else:\n",
    "        current_best = {'feature_map_reps': 2, 'ansatz_reps': 2, 'ansatz_type': 'RealAmplitudes'}\n",
    "        current_score = 0.4\n",
    "\n",
    "    adaptive_results = []\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        print(f\"  Adaptive iteration {i+1}/{n_iterations}: \", end=\"\")\n",
    "\n",
    "        # Generate candidate by perturbing current best\n",
    "        candidate = current_best.copy()\n",
    "\n",
    "        # Randomly perturb one parameter\n",
    "        param_to_change = np.random.choice(['feature_map_reps', 'ansatz_reps', 'ansatz_type'])\n",
    "\n",
    "        if param_to_change == 'feature_map_reps':\n",
    "            candidate['feature_map_reps'] = max(1, min(4, current_best['feature_map_reps'] + np.random.choice([-1, 0, 1])))\n",
    "        elif param_to_change == 'ansatz_reps':\n",
    "            candidate['ansatz_reps'] = max(1, min(5, current_best['ansatz_reps'] + np.random.choice([-1, 0, 1])))\n",
    "        else:\n",
    "            candidate['ansatz_type'] = np.random.choice(['RealAmplitudes', 'EfficientSU2'])\n",
    "\n",
    "        try:\n",
    "            # Test candidate\n",
    "            feature_map = ZZFeatureMap(feature_dimension=4, reps=candidate['feature_map_reps'])\n",
    "            if candidate['ansatz_type'] == 'RealAmplitudes':\n",
    "                ansatz = RealAmplitudes(num_qubits=4, reps=candidate['ansatz_reps'])\n",
    "            else:\n",
    "                ansatz = EfficientSU2(num_qubits=4, reps=candidate['ansatz_reps'])\n",
    "\n",
    "            vqc_adaptive = VQC(\n",
    "                sampler=StatevectorSampler(),\n",
    "                feature_map=feature_map,\n",
    "                ansatz=ansatz,\n",
    "                optimizer=COBYLA(maxiter=120)\n",
    "            )\n",
    "\n",
    "            vqc_adaptive.fit(X_train, y_train)\n",
    "            y_pred = vqc_adaptive.predict(X_test)\n",
    "            score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            adaptive_results.append({\n",
    "                'iteration': i,\n",
    "                'params': candidate,\n",
    "                'score': score\n",
    "            })\n",
    "\n",
    "            # Update current best if improved\n",
    "            if score > current_score:\n",
    "                current_best = candidate.copy()\n",
    "                current_score = score\n",
    "                print(f\"NEW BEST! Score: {score:.4f}\")\n",
    "            else:\n",
    "                print(f\"Score: {score:.4f}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed: {str(e)[:30]}...\")\n",
    "\n",
    "    return adaptive_results, current_best, current_score\n",
    "\n",
    "adaptive_results, final_best_params, final_best_score = adaptive_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5c355644-a270-4a1d-b0be-9955b2ce73d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "5c355644-a270-4a1d-b0be-9955b2ce73d5",
    "outputId": "0f8592e4-b3a4-4924-bbdb-d8e8d56e7355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HYPERPARAMETER TUNING RESULTS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Method                | Best Score | Improvement\n",
      "--------------------------------------------------\n",
      "Grid Search        | 0.8000    | +0.3667\n",
      "Optimizer Tuning   | 0.6667    | +0.2334\n",
      "Random Search      | 0.6000    | +0.1667\n",
      "Adaptive Tuning    | 0.8000    | +0.3667\n",
      "\n",
      "BEST OVERALL: Grid Search with 0.8000 accuracy\n",
      "Total improvement: +0.3667 (84.6%)\n",
      "\n",
      "Final best parameters: {'ansatz_reps': 2, 'ansatz_type': 'EfficientSU2', 'feature_map_reps': 2, 'optimizer_maxiter': 50}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# RESULTS SUMMARY\n",
    "# -----------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HYPERPARAMETER TUNING RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect all scores\n",
    "all_scores = []\n",
    "\n",
    "# Grid search results\n",
    "if grid_results:\n",
    "    grid_best = max(grid_results, key=lambda x: x['score'])\n",
    "    all_scores.append(('Grid Search', grid_best['score']))\n",
    "\n",
    "# Optimizer tuning results\n",
    "if optimizer_results:\n",
    "    opt_best = max(optimizer_results.items(), key=lambda x: x[1]['score'])\n",
    "    all_scores.append(('Optimizer Tuning', opt_best[1]['score']))\n",
    "\n",
    "# Random search results\n",
    "if random_results:\n",
    "    random_best = max(random_results, key=lambda x: x['score'])\n",
    "    all_scores.append(('Random Search', random_best['score']))\n",
    "\n",
    "# Adaptive results\n",
    "all_scores.append(('Adaptive Tuning', final_best_score))\n",
    "\n",
    "# Display results\n",
    "print(\"\\nMethod                | Best Score | Improvement\")\n",
    "print(\"-\" * 50)\n",
    "baseline = 0.4333\n",
    "for method, score in all_scores:\n",
    "    improvement = score - baseline\n",
    "    print(f\"{method:<18} | {score:.4f}    | +{improvement:.4f}\")\n",
    "\n",
    "# Overall best\n",
    "if all_scores:\n",
    "    overall_best = max(all_scores, key=lambda x: x[1])\n",
    "    total_improvement = overall_best[1] - baseline\n",
    "    print(f\"\\nBEST OVERALL: {overall_best[0]} with {overall_best[1]:.4f} accuracy\")\n",
    "    print(f\"Total improvement: +{total_improvement:.4f} ({(total_improvement/baseline)*100:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nFinal best parameters: {final_best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2a272a64-4474-45b2-b5ab-1207386866b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\safur\\Projects\\quantum-notebook\n",
      "Models will be saved in: C:\\Users\\safur\\Projects\\quantum-notebook\\extracted_models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# ===========================================\n",
    "# Creating a dedicated folder for models\n",
    "# ===========================================\n",
    "\n",
    "# Get current working directory (where your notebook is running)\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current working directory: {current_dir}\")\n",
    "\n",
    "# Create models folder\n",
    "models_folder = \"extracted_models\"\n",
    "models_path = os.path.join(current_dir, models_folder)\n",
    "os.makedirs(models_path, exist_ok=True)\n",
    "print(f\"Models will be saved in: {models_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bec3861d-df1b-4f77-b790-4e9a11a72865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed - Training: (120, 4), Test: (30, 4)\n",
      "Labels - Training: (120,), Test: (30,)\n",
      "Data is now consistent for classical model training\n"
     ]
    }
   ],
   "source": [
    "# Use the same dataset and split parameters from your successful quantum training\n",
    "X, y = X_final, y_final  # These should still be available from earlier cells\n",
    "\n",
    "# Recreate the exact same train-test split used throughout your notebook\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Apply the same scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Verify (this should show 120 and 30 samples)\n",
    "print(f\"Fixed - Training: {X_train_scaled.shape}, Test: {X_test_scaled.shape}\")\n",
    "print(f\"Labels - Training: {y_train.shape}, Test: {y_test.shape}\")\n",
    "print(\"Data is now consistent for classical model training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fb7763be-8ae4-44d4-9375-83b04cac05f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Classical Models...\n",
      "Classical models trained and ready for extraction\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# Extracting Classical Models\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\nExtracting Classical Models...\")\n",
    "\n",
    "# Train fresh classical models on your current data (to ensure they exist)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Using your existing X_train_scaled, X_test_scaled, y_train, y_test\n",
    "classical_models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "classical_models['logistic_regression'] = {\n",
    "    'model': lr_model,\n",
    "    'accuracy': lr_accuracy,\n",
    "    'predictions': lr_pred\n",
    "}\n",
    "\n",
    "# SVM\n",
    "svm_model = SVC(random_state=42, kernel='rbf')\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "svm_pred = svm_model.predict(X_test_scaled)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "classical_models['svm'] = {\n",
    "    'model': svm_model,\n",
    "    'accuracy': svm_accuracy,\n",
    "    'predictions': svm_pred\n",
    "}\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "classical_models['random_forest'] = {\n",
    "    'model': rf_model,\n",
    "    'accuracy': rf_accuracy,\n",
    "    'predictions': rf_pred\n",
    "}\n",
    "\n",
    "print(\"Classical models trained and ready for extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b7381193-3b99-452b-b5e9-74a9ce74db48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No gradient function provided, creating a gradient function. If your Sampler requires transpilation, please provide a pass manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: logistic_regression -> logistic_regression_20250820_205939.joblib (Accuracy: 0.7333)\n",
      "Saved: svm -> svm_20250820_205939.joblib (Accuracy: 0.9000)\n",
      "Saved: random_forest -> random_forest_20250820_205939.joblib (Accuracy: 0.8000)\n",
      "\n",
      " Extracting Best Quantum Model...\n",
      "Best quantum model found: 0.8000 accuracy\n",
      "Retraining best quantum model...\n",
      "Verified quantum model accuracy: 0.6000\n",
      "Failed to save quantum model: Can't get local object 'VQC._get_interpret.<locals>.parity'\n",
      "\n",
      "Saving preprocessing components...\n",
      "Saved: Preprocessing components -> preprocessing_20250820_205939.pkl\n",
      "\n",
      "Creating summary report...\n",
      "\n",
      "============================================================\n",
      "MODEL EXTRACTION COMPLETE!!!!!\n",
      "============================================================\n",
      "Location: C:\\Users\\safur\\Projects\\quantum-notebook\\extracted_models\n",
      "Summary: extraction_summary_20250820_205939.json\n",
      "\n",
      "Extracted Models:\n",
      "   1. logistic_regression_20250820_205939.joblib (1.0 KB)\n",
      "   2. svm_20250820_205939.joblib (4.7 KB)\n",
      "   3. random_forest_20250820_205939.joblib (246.4 KB)\n",
      "   4. extraction_summary_20250820_205939.json (0.9 KB)\n",
      "\n",
      "Best Classical: svm (0.9000)\n",
      "Best Quantum: 0.8000\n",
      "Overall Best: Classical\n",
      "\n",
      "To use these models later, navigate to: C:\\Users\\safur\\Projects\\quantum-notebook\\extracted_models\n",
      "Load with: joblib.load('filename.joblib') or pickle.load(open('filename.pkl', 'rb'))\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# STEP 3: Save Classical Models\n",
    "# ===========================================\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "classical_files = []\n",
    "\n",
    "for model_name, model_data in classical_models.items():\n",
    "    try:\n",
    "        # Create complete model package\n",
    "        model_package = {\n",
    "            'model': model_data['model'],\n",
    "            'accuracy': model_data['accuracy'],\n",
    "            'model_type': 'classical',\n",
    "            'model_name': model_name,\n",
    "            'timestamp': timestamp,\n",
    "            'training_samples': len(X_train_scaled),\n",
    "            'test_samples': len(X_test_scaled),\n",
    "            'features': X_train_scaled.shape[1]\n",
    "        }\n",
    "        \n",
    "        # Save with joblib (better for sklearn models)\n",
    "        filename = f\"{model_name}_{timestamp}.joblib\"\n",
    "        filepath = os.path.join(models_path, filename)\n",
    "        \n",
    "        joblib.dump(model_package, filepath)\n",
    "        classical_files.append(filepath)\n",
    "        \n",
    "        print(f\"Saved: {model_name} -> {filename} (Accuracy: {model_data['accuracy']:.4f})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save {model_name}: {str(e)}\")\n",
    "\n",
    "# ===========================================\n",
    "# STEP 4: Find and Extract Best Quantum Model\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n Extracting Best Quantum Model...\")\n",
    "\n",
    "# Find the best quantum model from your hyperparameter tuning results\n",
    "best_quantum_model = None\n",
    "best_quantum_accuracy = 0\n",
    "best_quantum_params = None\n",
    "\n",
    "# Check if you have results from hyperparameter tuning\n",
    "if 'grid_results' in globals() and grid_results:\n",
    "    # Find best from grid search\n",
    "    best_result = max(grid_results, key=lambda x: x['score'])\n",
    "    best_quantum_accuracy = best_result['score']\n",
    "    best_quantum_params = best_result['params']\n",
    "    print(f\"Best quantum model found: {best_quantum_accuracy:.4f} accuracy\")\n",
    "    \n",
    "    # Recreate the best model\n",
    "    from qiskit.primitives import StatevectorSampler\n",
    "    from qiskit_machine_learning.algorithms.classifiers import VQC\n",
    "    from qiskit.circuit.library import ZZFeatureMap, RealAmplitudes, EfficientSU2\n",
    "    from qiskit_machine_learning.optimizers import COBYLA\n",
    "    \n",
    "    try:\n",
    "        # Recreate feature map\n",
    "        feature_map = ZZFeatureMap(\n",
    "            feature_dimension=4,\n",
    "            reps=best_quantum_params['feature_map_reps']\n",
    "        )\n",
    "        \n",
    "        # Recreate ansatz\n",
    "        if best_quantum_params['ansatz_type'] == 'RealAmplitudes':\n",
    "            ansatz = RealAmplitudes(num_qubits=4, reps=best_quantum_params['ansatz_reps'])\n",
    "        else:\n",
    "            ansatz = EfficientSU2(num_qubits=4, reps=best_quantum_params['ansatz_reps'])\n",
    "        \n",
    "        # Recreate optimizer\n",
    "        optimizer = COBYLA(maxiter=best_quantum_params['optimizer_maxiter'])\n",
    "        \n",
    "        # Create and train the best model\n",
    "        best_quantum_model = VQC(\n",
    "            sampler=StatevectorSampler(),\n",
    "            feature_map=feature_map,\n",
    "            ansatz=ansatz,\n",
    "            optimizer=optimizer\n",
    "        )\n",
    "        \n",
    "        print(\"Retraining best quantum model...\")\n",
    "        best_quantum_model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Verify accuracy\n",
    "        quantum_pred = best_quantum_model.predict(X_test_scaled)\n",
    "        verified_accuracy = accuracy_score(y_test, quantum_pred)\n",
    "        print(f\"Verified quantum model accuracy: {verified_accuracy:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to recreate best quantum model: {str(e)}\")\n",
    "        # Fall back to any available quantum model\n",
    "        if 'vqc3' in globals():\n",
    "            best_quantum_model = vqc3\n",
    "            quantum_pred = best_quantum_model.predict(X_test_scaled)\n",
    "            best_quantum_accuracy = accuracy_score(y_test, quantum_pred)\n",
    "            best_quantum_params = {'fallback': 'using_vqc3'}\n",
    "            print(f\"Using fallback model with accuracy: {best_quantum_accuracy:.4f}\")\n",
    "\n",
    "# ===========================================\n",
    "# STEP 5: Save Best Quantum Model\n",
    "# ===========================================\n",
    "\n",
    "quantum_file = None\n",
    "if best_quantum_model is not None:\n",
    "    try:\n",
    "        quantum_package = {\n",
    "            'model': best_quantum_model,\n",
    "            'accuracy': best_quantum_accuracy,\n",
    "            'parameters': best_quantum_params,\n",
    "            'model_type': 'quantum',\n",
    "            'model_name': 'best_vqc',\n",
    "            'timestamp': timestamp,\n",
    "            'training_samples': len(X_train_scaled),\n",
    "            'test_samples': len(X_test_scaled),\n",
    "            'features': X_train_scaled.shape[1],\n",
    "            'qubits': 4\n",
    "        }\n",
    "        \n",
    "        filename = f\"best_quantum_model_{timestamp}.pkl\"\n",
    "        filepath = os.path.join(models_path, filename)\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(quantum_package, f)\n",
    "        \n",
    "        quantum_file = filepath\n",
    "        print(f\"Saved: Best Quantum Model -> {filename} (Accuracy: {best_quantum_accuracy:.4f})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save quantum model: {str(e)}\")\n",
    "else:\n",
    "    print(\"No quantum model available to save\")\n",
    "\n",
    "# ===========================================\n",
    "# STEP 6: Save Preprocessing Components\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\nSaving preprocessing components...\")\n",
    "\n",
    "try:\n",
    "    preprocessing_package = {\n",
    "        'scaler': scaler,  # Your StandardScaler\n",
    "        'feature_names': [f'feature_{i}' for i in range(X_train_scaled.shape[1])],\n",
    "        'dataset_info': {\n",
    "            'name': dataset_name if 'dataset_name' in globals() else 'synthetic',\n",
    "            'n_samples': len(X),\n",
    "            'n_features': X.shape[1],\n",
    "            'train_size': len(X_train_scaled),\n",
    "            'test_size': len(X_test_scaled)\n",
    "        },\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "    \n",
    "    filename = f\"preprocessing_{timestamp}.pkl\"\n",
    "    filepath = os.path.join(models_path, filename)\n",
    "    \n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(preprocessing_package, f)\n",
    "    \n",
    "    print(f\"Saved: Preprocessing components -> {filename}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Failed to save preprocessing: {str(e)}\")\n",
    "\n",
    "# ===========================================\n",
    "# STEP 7: Create Summary Report\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\nCreating summary report...\")\n",
    "\n",
    "summary = {\n",
    "    'experiment_name': 'Healora Quantum ML Comparison',\n",
    "    'timestamp': timestamp,\n",
    "    'extraction_location': models_path,\n",
    "    'classical_models': {\n",
    "        name: {\n",
    "            'accuracy': data['accuracy'],\n",
    "            'file': f\"{name}_{timestamp}.joblib\"\n",
    "        } for name, data in classical_models.items()\n",
    "    },\n",
    "    'quantum_model': {\n",
    "        'accuracy': best_quantum_accuracy,\n",
    "        'parameters': best_quantum_params,\n",
    "        'file': f\"best_quantum_model_{timestamp}.pkl\" if quantum_file else None\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'total_samples': len(X) if 'X' in globals() else 'unknown',\n",
    "        'features': X.shape[1] if 'X' in globals() else 'unknown',\n",
    "        'train_samples': len(X_train_scaled),\n",
    "        'test_samples': len(X_test_scaled)\n",
    "    },\n",
    "    'best_classical': max(classical_models.items(), key=lambda x: x[1]['accuracy'])[0],\n",
    "    'best_overall': 'classical' if max(classical_models.values(), key=lambda x: x['accuracy'])['accuracy'] > best_quantum_accuracy else 'quantum'\n",
    "}\n",
    "\n",
    "summary_filename = f\"extraction_summary_{timestamp}.json\"\n",
    "summary_filepath = os.path.join(models_path, summary_filename)\n",
    "\n",
    "with open(summary_filepath, 'w') as f:\n",
    "    json.dump(summary, f, indent=2, default=str)\n",
    "\n",
    "# ===========================================\n",
    "# STEP 8: Final Report\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EXTRACTION COMPLETE!!!!!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Location: {models_path}\")\n",
    "print(f\"Summary: {summary_filename}\")\n",
    "print(\"\\nExtracted Models:\")\n",
    "\n",
    "# List all files created\n",
    "all_files = classical_files + ([quantum_file] if quantum_file else []) + [summary_filepath]\n",
    "for i, filepath in enumerate(all_files, 1):\n",
    "    filename = os.path.basename(filepath)\n",
    "    file_size = os.path.getsize(filepath) / 1024  # KB\n",
    "    print(f\"   {i}. {filename} ({file_size:.1f} KB)\")\n",
    "\n",
    "print(f\"\\nBest Classical: {summary['best_classical']} ({classical_models[summary['best_classical']]['accuracy']:.4f})\")\n",
    "print(f\"Best Quantum: {best_quantum_accuracy:.4f}\")\n",
    "print(f\"Overall Best: {summary['best_overall'].title()}\")\n",
    "\n",
    "print(f\"\\nTo use these models later, navigate to: {models_path}\")\n",
    "print(\"Load with: joblib.load('filename.joblib') or pickle.load(open('filename.pkl', 'rb'))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a4b9b-0aa8-4131-aeec-380cec625846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (quantum-env)",
   "language": "python",
   "name": "quantum-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
